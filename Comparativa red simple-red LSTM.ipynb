{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "a0x5NHY2xPhc"
   },
   "source": [
    "# Clasificador de tweets.\n",
    "\n",
    "Dado el siguiente conjunto de datos\n",
    "\n",
    "http://help.sentiment140.com/for-students/\n",
    "\n",
    "Crear una red neuronal capaz de clasificar los tweets según la connotación del contenido (negativo/neutral/positivo).\n",
    "\n",
    "Será necesario utilizar técnicas de Word Embedding para la codificación del contenido. Utilizar la librería keras para obtener una embedding matrix propia y comparar los resultados obtenidos con un embedding matrix preentrenado de tipo word2vec de vuestra elección.\n",
    "\n",
    "Para las unidades de la red neuronal recurrente se han utilizado dos tipos diferentes Simple, y LSTM , para comparar los resultados obtenidos.\n",
    "\n",
    "Comentarios sobre el data set:\n",
    "\n",
    "Como habréis visto en la definción del problema existen tres clases diferentes. Pero estas tres clases, solo aparecen en los datos de testeo, no en los de entrenamiento. Por tanto la precisión será siempre menor. La solución sería obtener más datos o realizar un muestreo de los datos para generar de nuevo los conjuntos de entrenamiento y testeo, pero esta última solución podría producir un fenomeno de infrarrepresentación de la clase neutro. Es por eso que se ha optado por eliminar aquellas tuplas de clase neutro del conjunto de testeo y se ha planteado como un problema binario (positivo-negativo)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.1.1'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import flask\n",
    "flask.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "msmaNlbsWId5"
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 50
    },
    "colab_type": "code",
    "id": "IPkqGSNKxVVO",
    "outputId": "e084c933-4f02-4879-cb8e-5ee794f46c4e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Número de Tweets de entrenamiento: 1600000\n",
      "Número de Tweets de test: 359\n"
     ]
    }
   ],
   "source": [
    "#Tweets de entrenamiento.\n",
    "tweets_train = './/data/traindatanormalized2.csv'\n",
    "\n",
    "df_train = pd.read_csv(tweets_train)\n",
    "df_train.Text=df_train.Text.astype(str)\n",
    "df_train['Sentiment'] = df_train['Sentiment'].replace({0: 0, 4: 1})\n",
    "df_train = df_train.sample(frac=1).reset_index(drop=True)\n",
    "tweets_train = [tuple(x) for x in df_train.values]\n",
    "\n",
    "#Tweets de prueba.\n",
    "tweets_test = './/data/testdatanormalized2.csv'\n",
    "\n",
    "df_test = pd.read_csv(tweets_test)\n",
    "df_test.Text=df_test.Text.astype(str)\n",
    "df_test = df_test.drop(df_test[df_test['Sentiment']==2].index)\n",
    "df_test['Sentiment'] = df_test['Sentiment'].replace({0: 0, 4: 1})\n",
    "tweets_test = [tuple(x) for x in df_test.values]\n",
    "\n",
    "print('Número de Tweets de entrenamiento: {num}'.format(num=len(tweets_train)))\n",
    "print('Número de Tweets de test: {num}'.format(num=len(tweets_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "5rjNXnze-2Ls"
   },
   "source": [
    "## Normalización\n",
    "Los datos se han normalizado con este código pero en un archivo de tipo .py con spyder, ya que al tratar con un dataset tan ammplio, preferí normalizarlo y guardarlo, para posteriormente poder trabajar con el dataset ya normalizado.\n",
    "\n",
    "* Para este ejemplo haremos uso de ***spaCy***, pero en este caso tenemos que utilizar (e importar) el modelo para Inglés. \n",
    "\n",
    "* Para ***normalizar*** los tweets realizaremos las siguientes acciones:\n",
    "    1. Pasamos las frases a minúsculas.\n",
    "    2. Eliminamos los signos de puntuación.\n",
    "    3. Eliminamos las palabras con menos de 3 caracteres.\n",
    "    4. Eliminamos las Stop-Words.\n",
    "    5. Eliminamos las palabras que empiecen por '@' o 'http'.\n",
    "    6. Pasamos la palabra a su lema.\n",
    "\n",
    "\n",
    "* Todos estos pasos los vamos a realizar en una misma función:\n",
    "\n",
    ":\n",
    "    \n",
    "    import spacy\n",
    "    nlp = spacy.load('en_core_web_sm')\n",
    "\n",
    "* Divido los datos en dos listas:\n",
    "     * X_train: los tweets de entrenamiento.\n",
    "     * y_train: target (polaridad) de entrenamiento.\n",
    "     \n",
    ":\n",
    "    \n",
    "    X_train = [doc[5] for doc in tweets_train]\n",
    "    y_train = [doc[0] for doc in tweets_train]\n",
    "\n",
    "* Realizamos la misma acción para los datos de test:\n",
    "     * X_test: los tweets de test.\n",
    "     * y_test: target (polaridad) de test.\n",
    "     \n",
    ":\n",
    "    \n",
    "    X_test = [doc[5] for doc in tweets_test]\n",
    "    y_test = [doc[0] for doc in tweets_test]\n",
    "\n",
    "* Normalizamos la lista de frases y devolvemos la misma lista de frases normalizada:\n",
    "\n",
    ":\n",
    "    \n",
    "    def normalize(sentenses):\n",
    "    \n",
    "      for index, sentense in enumerate(sentenses): \n",
    "        \n",
    "          sentense = nlp(sentense.lower()) \n",
    "          sentenses[index] = \" \".join([word.lemma_ for word in sentense if (not word.is_punct) #Eliminamos signos.\n",
    "                                     and (len(word.text) > 2) and (not word.is_stop) #Eliminamos palabras cortas.\n",
    "                                     and (not word.text.startswith('@')) and (not word.text.startswith('http'))]) #Eliminamos @ y http.\n",
    "                                     \n",
    "* Normalizamos las frases:\n",
    "                                     \n",
    "       X_train = normalize(X_train)\n",
    "       X_test = normalize(X_test)\n",
    "       \n",
    "* Y lo guardamos:\n",
    "       \n",
    "       df_train.to_csv('.//trainandtestdata/traindatanormalized.csv')\n",
    "       df_test.to_csv('.//trainandtestdata/testdatanormalized.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 343
    },
    "colab_type": "code",
    "id": "FMMrTye0L1X7",
    "outputId": "9bb61d78-3c11-4aab-941f-292592a784f1"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2207205191</td>\n",
       "      <td>Wed Jun 17 07:37:34 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>turdboy420</td>\n",
       "      <td>barely learn quot;abc alphabet song&amp;quot parod...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1973460372</td>\n",
       "      <td>Sat May 30 11:11:27 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>monicananz</td>\n",
       "      <td>pam gooood miss</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2015301421</td>\n",
       "      <td>Wed Jun 03 04:17:23 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>nevitsky</td>\n",
       "      <td>totally join reception</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1972346610</td>\n",
       "      <td>Sat May 30 09:03:13 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>bizzrock</td>\n",
       "      <td>love saturday run pick old college friend let ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>2184602030</td>\n",
       "      <td>Mon Jun 15 16:08:54 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>Mooblr</td>\n",
       "      <td>hey new follower come introduce</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>1686703449</td>\n",
       "      <td>Sun May 03 06:28:18 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>thoughtprinter</td>\n",
       "      <td>dislike science actually dislike study</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1969449962</td>\n",
       "      <td>Sat May 30 00:04:29 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>AndrewVassallo</td>\n",
       "      <td>rise amp shine second element miss anyway go j...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>1985803184</td>\n",
       "      <td>Sun May 31 17:48:12 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>mariahisazebra</td>\n",
       "      <td>check email</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>2286097474</td>\n",
       "      <td>Mon Jun 22 15:59:40 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>lexytime</td>\n",
       "      <td>miss</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>2056645891</td>\n",
       "      <td>Sat Jun 06 11:31:47 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>watudoinsammie</td>\n",
       "      <td>mmmm noodle</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Sentiment           1                             2         3  \\\n",
       "0          0  2207205191  Wed Jun 17 07:37:34 PDT 2009  NO_QUERY   \n",
       "1          0  1973460372  Sat May 30 11:11:27 PDT 2009  NO_QUERY   \n",
       "2          1  2015301421  Wed Jun 03 04:17:23 PDT 2009  NO_QUERY   \n",
       "3          1  1972346610  Sat May 30 09:03:13 PDT 2009  NO_QUERY   \n",
       "4          1  2184602030  Mon Jun 15 16:08:54 PDT 2009  NO_QUERY   \n",
       "5          0  1686703449  Sun May 03 06:28:18 PDT 2009  NO_QUERY   \n",
       "6          0  1969449962  Sat May 30 00:04:29 PDT 2009  NO_QUERY   \n",
       "7          1  1985803184  Sun May 31 17:48:12 PDT 2009  NO_QUERY   \n",
       "8          0  2286097474  Mon Jun 22 15:59:40 PDT 2009  NO_QUERY   \n",
       "9          1  2056645891  Sat Jun 06 11:31:47 PDT 2009  NO_QUERY   \n",
       "\n",
       "                4                                               Text  \n",
       "0      turdboy420  barely learn quot;abc alphabet song&quot parod...  \n",
       "1      monicananz                                    pam gooood miss  \n",
       "2        nevitsky                             totally join reception  \n",
       "3        bizzrock  love saturday run pick old college friend let ...  \n",
       "4          Mooblr                    hey new follower come introduce  \n",
       "5  thoughtprinter             dislike science actually dislike study  \n",
       "6  AndrewVassallo  rise amp shine second element miss anyway go j...  \n",
       "7  mariahisazebra                                        check email  \n",
       "8        lexytime                                               miss  \n",
       "9  watudoinsammie                                        mmmm noodle  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train = df_train.drop('Unnamed: 0', 1)\n",
    "df_train.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 343
    },
    "colab_type": "code",
    "id": "VQ6mwrODW5Gd",
    "outputId": "eff901c5-e2b6-4d2e-9a89-04946e06fe0c"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Mon May 11 03:17:40 UTC 2009</td>\n",
       "      <td>kindle2</td>\n",
       "      <td>tpryan</td>\n",
       "      <td>love kindle2 cool fantastic right</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>Mon May 11 03:18:03 UTC 2009</td>\n",
       "      <td>kindle2</td>\n",
       "      <td>vcu451</td>\n",
       "      <td>read kindle2 love lee child good read</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>Mon May 11 03:18:54 UTC 2009</td>\n",
       "      <td>kindle2</td>\n",
       "      <td>chadfu</td>\n",
       "      <td>assesment kindle2 fucking rock</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>Mon May 11 03:19:04 UTC 2009</td>\n",
       "      <td>kindle2</td>\n",
       "      <td>SIX15</td>\n",
       "      <td>love kindle2 month look new big huge need remorse</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>Mon May 11 03:21:41 UTC 2009</td>\n",
       "      <td>kindle2</td>\n",
       "      <td>yamarama</td>\n",
       "      <td>fair kindle2 think perfect</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>Mon May 11 03:22:00 UTC 2009</td>\n",
       "      <td>kindle2</td>\n",
       "      <td>GeorgeVHulme</td>\n",
       "      <td>big happy kindle2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>Mon May 11 03:22:30 UTC 2009</td>\n",
       "      <td>aig</td>\n",
       "      <td>Seth937</td>\n",
       "      <td>fuck economy hate aig non loan give ass</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>Mon May 11 03:26:10 UTC 2009</td>\n",
       "      <td>jquery</td>\n",
       "      <td>dcostalis</td>\n",
       "      <td>jquery new good friend</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>Mon May 11 03:27:15 UTC 2009</td>\n",
       "      <td>twitter</td>\n",
       "      <td>PJ_King</td>\n",
       "      <td>love twitter</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>Mon May 11 03:29:20 UTC 2009</td>\n",
       "      <td>obama</td>\n",
       "      <td>mandanicole</td>\n",
       "      <td>love obama make joke</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Sentiment   1                             2        3             4  \\\n",
       "0          1   3  Mon May 11 03:17:40 UTC 2009  kindle2        tpryan   \n",
       "1          1   4  Mon May 11 03:18:03 UTC 2009  kindle2        vcu451   \n",
       "2          1   5  Mon May 11 03:18:54 UTC 2009  kindle2        chadfu   \n",
       "3          1   6  Mon May 11 03:19:04 UTC 2009  kindle2         SIX15   \n",
       "4          1   7  Mon May 11 03:21:41 UTC 2009  kindle2      yamarama   \n",
       "5          1   8  Mon May 11 03:22:00 UTC 2009  kindle2  GeorgeVHulme   \n",
       "6          0   9  Mon May 11 03:22:30 UTC 2009      aig       Seth937   \n",
       "7          1  10  Mon May 11 03:26:10 UTC 2009   jquery     dcostalis   \n",
       "8          1  11  Mon May 11 03:27:15 UTC 2009  twitter       PJ_King   \n",
       "9          1  12  Mon May 11 03:29:20 UTC 2009    obama   mandanicole   \n",
       "\n",
       "                                                Text  \n",
       "0                  love kindle2 cool fantastic right  \n",
       "1              read kindle2 love lee child good read  \n",
       "2                     assesment kindle2 fucking rock  \n",
       "3  love kindle2 month look new big huge need remorse  \n",
       "4                         fair kindle2 think perfect  \n",
       "5                                  big happy kindle2  \n",
       "6            fuck economy hate aig non loan give ass  \n",
       "7                             jquery new good friend  \n",
       "8                                       love twitter  \n",
       "9                               love obama make joke  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test = df_test.drop('Unnamed: 0', 1)\n",
    "df_test.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "GmHXJF_NXBn_"
   },
   "outputs": [],
   "source": [
    "# Divido los datos en dos listas \n",
    "#     X_train: los tweets de entrenamiento\n",
    "#     y_train: target (polaridad) de entrenamiento\n",
    "X_train = [doc[6] for doc in tweets_train]\n",
    "y_train = [doc[1] for doc in tweets_train]\n",
    "\n",
    "#Realizamos la misma acción para los datos de test. \n",
    "#     X_test: los tweets de test\n",
    "#     y_test: target (polaridad) de test\n",
    "X_test = [doc[6] for doc in tweets_test]\n",
    "y_test = [doc[1] for doc in tweets_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "colab_type": "code",
    "id": "LymXs3OgXDM1",
    "outputId": "3df3f7ce-7416-4e31-a1cb-a0dcfccf2ac0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['barely learn quot;abc alphabet song&quot parody quot;twinkle twinkle lil star&quot pretty mind blow tell', 'pam gooood miss', 'totally join reception', 'love saturday run pick old college friend let sweet tea vodka start flow', 'hey new follower come introduce']\n"
     ]
    }
   ],
   "source": [
    "print(X_train[0:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "xUWKNnUxS_Be"
   },
   "source": [
    "## Bolsa de palabras\n",
    "* Escogemos las 500 palabras más frecuentes.\n",
    "* Tokenizamos los datos de entrenamiento.\n",
    "* Pasamos las palabras al número de veces que se encuentran en los tweets.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "SxIfUYQsETUG",
    "outputId": "132a8ea9-7c52-449e-998a-effd75c18a16"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "#Bolsa de palabras\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.utils import np_utils\n",
    "\n",
    "#Bolsa de palabras.\n",
    "max_words = 500 #Escogemos las 500 más frecuentes.\n",
    "tokenizer = Tokenizer(num_words=max_words)\n",
    "tokenizer.fit_on_texts(X_train)\n",
    "#tokenizer.fit_on_texts(X_test)\n",
    "\n",
    "X_matrix = tokenizer.texts_to_matrix(X_train, mode='count')\n",
    "X_matrix_test = tokenizer.texts_to_matrix(X_test, mode='count')\n",
    "\n",
    "#X_train = np.array(X_train)\n",
    "#X_test = np.array(X_test)\n",
    "\n",
    "# Codificación del Target\n",
    "encoder = LabelEncoder()\n",
    "encoder.fit(y_train)\n",
    "y_train = encoder.transform(y_train)\n",
    "y_test = encoder.transform(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "81APsq6vGBaw"
   },
   "source": [
    "Ahora tenemos el target codificado en 0 para sentimiento negativo y 1 para el sentimiento positivo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Mf0-Av1-W5Gy"
   },
   "source": [
    "## Red Simple.\n",
    "* Una vez creada la red mostramos su arquitectura:\n",
    "    - 500 Neuronas de entrada\n",
    "    - Capa 2: 20 Neuronas\n",
    "    - Conexiones \"capa de entrada -> Capa 2\" = (500*20) + 20 = 10020 Conexiones\n",
    "    - Capa 3: 10 Neuronas\n",
    "    - Conexiones \"Capa 2 -> Capa 3\" = (20*10) + 10 = 210 Conexiones\n",
    "    - Capa de salida: 1 Neuronas\n",
    "    - Conexiones \"Capa 3 -> Capa de salida\" = (10*1) + 1 = 11 Conexiones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 356
    },
    "colab_type": "code",
    "id": "5S8PGYhfW5Gz",
    "outputId": "629b38bc-869e-4f84-e6e5-2cae7a8ce8ce"
   },
   "outputs": [],
   "source": [
    "#Red Neuronal.\n",
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "\n",
    "np.random.seed(9)\n",
    "model = Sequential() #Contenedor genérico.\n",
    "model.add(Dense(20, activation='relu', input_dim=max_words))\n",
    "model.add(Dropout(0.1))\n",
    "model.add(Dense(10, activation='relu'))\n",
    "model.add(Dropout(0.1))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 302
    },
    "colab_type": "code",
    "id": "blvYA3fMGK4f",
    "outputId": "e918ba94-6790-4b81-e292-e7ffad0ffb2c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 20)                10020     \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 20)                0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                210       \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 10)                0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1)                 11        \n",
      "=================================================================\n",
      "Total params: 10,241\n",
      "Trainable params: 10,241\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 722
    },
    "colab_type": "code",
    "id": "_TsWCRbXGNey",
    "outputId": "16cdfc28-fca8-45a7-d9c1-6c42b6373063"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1440000 samples, validate on 160000 samples\n",
      "Epoch 1/20\n",
      "1440000/1440000 [==============================] - 83s 57us/step - loss: 0.5482 - accuracy: 0.7137 - val_loss: 0.5384 - val_accuracy: 0.7190\n",
      "Epoch 2/20\n",
      "1440000/1440000 [==============================] - 66s 46us/step - loss: 0.5402 - accuracy: 0.7192 - val_loss: 0.5360 - val_accuracy: 0.7207\n",
      "Epoch 3/20\n",
      "1440000/1440000 [==============================] - 68s 47us/step - loss: 0.5381 - accuracy: 0.7210 - val_loss: 0.5347 - val_accuracy: 0.7221\n",
      "Epoch 4/20\n",
      "1440000/1440000 [==============================] - 57s 40us/step - loss: 0.5370 - accuracy: 0.7218 - val_loss: 0.5345 - val_accuracy: 0.7228\n",
      "Epoch 5/20\n",
      "1440000/1440000 [==============================] - 60s 42us/step - loss: 0.5359 - accuracy: 0.7229 - val_loss: 0.5340 - val_accuracy: 0.7217\n",
      "Epoch 6/20\n",
      "1440000/1440000 [==============================] - 59s 41us/step - loss: 0.5352 - accuracy: 0.7229 - val_loss: 0.5342 - val_accuracy: 0.7229\n",
      "Epoch 7/20\n",
      "1440000/1440000 [==============================] - 58s 40us/step - loss: 0.5348 - accuracy: 0.7233 - val_loss: 0.5335 - val_accuracy: 0.7226\n",
      "Epoch 8/20\n",
      "1440000/1440000 [==============================] - 61s 42us/step - loss: 0.5344 - accuracy: 0.7238 - val_loss: 0.5340 - val_accuracy: 0.7228\n",
      "Epoch 9/20\n",
      "1440000/1440000 [==============================] - 63s 44us/step - loss: 0.5343 - accuracy: 0.7235 - val_loss: 0.5336 - val_accuracy: 0.7224\n",
      "Epoch 10/20\n",
      "1440000/1440000 [==============================] - 72s 50us/step - loss: 0.5338 - accuracy: 0.7239 - val_loss: 0.5333 - val_accuracy: 0.7227\n",
      "Epoch 11/20\n",
      "1440000/1440000 [==============================] - 65s 45us/step - loss: 0.5337 - accuracy: 0.7241 - val_loss: 0.5333 - val_accuracy: 0.7228\n",
      "Epoch 12/20\n",
      "1440000/1440000 [==============================] - 68s 47us/step - loss: 0.5335 - accuracy: 0.7240 - val_loss: 0.5334 - val_accuracy: 0.7220\n",
      "Epoch 13/20\n",
      "1440000/1440000 [==============================] - 66s 46us/step - loss: 0.5333 - accuracy: 0.7244 - val_loss: 0.5334 - val_accuracy: 0.7228\n",
      "Epoch 14/20\n",
      "1440000/1440000 [==============================] - 66s 46us/step - loss: 0.5333 - accuracy: 0.7245 - val_loss: 0.5333 - val_accuracy: 0.7230\n",
      "Epoch 15/20\n",
      "1440000/1440000 [==============================] - 66s 46us/step - loss: 0.5332 - accuracy: 0.7245 - val_loss: 0.5333 - val_accuracy: 0.7222\n",
      "Epoch 16/20\n",
      "1440000/1440000 [==============================] - 70s 49us/step - loss: 0.5331 - accuracy: 0.7245 - val_loss: 0.5335 - val_accuracy: 0.7226\n",
      "Epoch 17/20\n",
      "1440000/1440000 [==============================] - 67s 47us/step - loss: 0.5330 - accuracy: 0.7248 - val_loss: 0.5334 - val_accuracy: 0.7226\n",
      "Epoch 18/20\n",
      "1440000/1440000 [==============================] - 70s 48us/step - loss: 0.5327 - accuracy: 0.7249 - val_loss: 0.5335 - val_accuracy: 0.7228\n",
      "Epoch 19/20\n",
      "1440000/1440000 [==============================] - 59s 41us/step - loss: 0.5327 - accuracy: 0.7248 - val_loss: 0.5333 - val_accuracy: 0.7222\n",
      "Epoch 20/20\n",
      "1440000/1440000 [==============================] - 57s 40us/step - loss: 0.5327 - accuracy: 0.7249 - val_loss: 0.5332 - val_accuracy: 0.7224\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x1d70036a748>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Entrenamos la red neuronal.\n",
    "model.fit(X_matrix, y_train, batch_size=64, verbose=1, epochs=20, validation_split=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 269
    },
    "colab_type": "code",
    "id": "Gu0qRLX_6mUY",
    "outputId": "f5d4694f-9cb2-4c8c-9da0-fc32c96ace45"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 1 1 1]\n",
      "[1 0 1 1 1]\n",
      "Accuracy: 0.7276\n",
      "F1: 0.7272\n",
      "Precision: 0.7291\n",
      "Recall: 0.7276\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.69      0.72    800000\n",
      "           1       0.71      0.77      0.74    800000\n",
      "\n",
      "    accuracy                           0.73   1600000\n",
      "   macro avg       0.73      0.73      0.73   1600000\n",
      "weighted avg       0.73      0.73      0.73   1600000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, confusion_matrix, classification_report\n",
    "\n",
    "y_true = encoder.inverse_transform(y_train.reshape(-1))\n",
    "\n",
    "print(y_true[0:5])\n",
    "\n",
    "y_pred = model.predict_classes(X_matrix)\n",
    "y_pred = encoder.inverse_transform(y_pred.reshape(-1))\n",
    "\n",
    "print(y_pred[0:5])\n",
    "\n",
    "print('Accuracy: {acc:0.4f}'.format(acc=accuracy_score(y_true=y_true, y_pred=y_pred)))\n",
    "print('F1: {f1:0.4f}'.format(f1=f1_score(y_true=y_true, y_pred=y_pred, average='weighted')))\n",
    "print('Precision: {pre:0.4f}'.format(pre=precision_score(y_true=y_true, y_pred=y_pred, average='weighted')))\n",
    "print('Recall: {rec:0.4f}'.format(rec=recall_score(y_true=y_true, y_pred=y_pred, average='weighted')))\n",
    "print(classification_report(y_true=y_true, y_pred=y_pred))\n",
    "confusion_matrix = confusion_matrix(y_true=y_true, y_pred=y_pred, labels=[0, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 311
    },
    "colab_type": "code",
    "id": "tK9wpS2gGU2h",
    "outputId": "d5a6e895-8911-4358-c8e2-3be01854cca4"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import itertools\n",
    "\n",
    "def plot_confusion_matrix(cm, classes, title, cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    \"\"\"\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i, j], 'd'), horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "\n",
    "plt.figure()\n",
    "plot_confusion_matrix(confusion_matrix, classes=['negativo', 'positivo'],\n",
    "                      title='Matriz de Confusión')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "qQwPNYEs-PQA"
   },
   "source": [
    "## Red Recurrente LSTM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Número de Tweets de entrenamiento: 1600000\n",
      "Número de Tweets de test: 359\n"
     ]
    }
   ],
   "source": [
    "#Tweets de entrenamiento.\n",
    "tweets_train = './/data/traindatanormalized2.csv'\n",
    "\n",
    "df_train = pd.read_csv(tweets_train)\n",
    "df_train.Text=df_train.Text.astype(str)\n",
    "df_train['Sentiment'] = df_train['Sentiment'].replace({0: 0, 4: 1})\n",
    "df_train = df_train.sample(frac=1).reset_index(drop=True)\n",
    "df_train = df_train.drop('Unnamed: 0', 1)\n",
    "\n",
    "\n",
    "#Tweets de prueba.\n",
    "tweets_test = './/data/testdatanormalized2.csv'\n",
    "\n",
    "df_test = pd.read_csv(tweets_test)\n",
    "df_test.Text=df_test.Text.astype(str)\n",
    "df_test = df_test.drop(df_test[df_test['Sentiment']==2].index)\n",
    "df_test['Sentiment'] = df_test['Sentiment'].replace({0: 0, 4: 1})\n",
    "df_test = df_test.drop('Unnamed: 0', 1)\n",
    "\n",
    "print('Número de Tweets de entrenamiento: {num}'.format(num=len(df_train['Sentiment'])))\n",
    "print('Número de Tweets de test: {num}'.format(num=len(df_test['Sentiment'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Forma de las etiquetas del tensor: (1600000,)\n",
      "Forma de las etiquetas del tensor: (359,)\n"
     ]
    }
   ],
   "source": [
    "#Bolsa de palabras\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.utils import np_utils\n",
    "\n",
    "#Bolsa de palabras.\n",
    "max_words = 500 #Escogemos las 500 más frecuentes.\n",
    "tokenizer = Tokenizer(num_words=max_words)\n",
    "tokenizer.fit_on_texts(df_train['Text'].values)\n",
    "\n",
    "# Codificación del Target\n",
    "encoder = LabelEncoder()\n",
    "encoder.fit(df_train['Sentiment'].values)\n",
    "y_train = encoder.transform(df_train['Sentiment'].values)\n",
    "y_test = encoder.transform(df_test['Sentiment'].values)\n",
    "\n",
    "# Codificación del Target\n",
    "#y_train = pd.get_dummies(df_train['Sentiment'].values)\n",
    "print('Forma de las etiquetas del tensor:', y_train.shape)\n",
    "\n",
    "#y_test = pd.get_dummies(df_test['Sentiment'].values)\n",
    "print('Forma de las etiquetas del tensor:', y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hasta ahora hemos realizado el mismo trabajo que haríamos para la red simple: \n",
    "\n",
    "Los datos han sido previeamente tratados, por eso se utiliza el archivo \"traindatanormalized2\" y \"testdatanormalized2\".\n",
    "* Importamos los datos, separando una muestra para entrenar la red y otra para validar el entrenamiento.\n",
    "* Creamos una bolsa de 500 palabras (se podrían escoger más, lo que aumentaría la precisión de la red, pero ralentiza todo el proceso)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 278068 unique tokens.\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "# documentos pad con una longitud máxima de 4 palabras\n",
    "max_length = 250\n",
    "\n",
    "X_train = tokenizer.texts_to_sequences(df_train['Text'].values)\n",
    "X_test = tokenizer.texts_to_sequences(df_test['Text'].values)\n",
    "\n",
    "X_train = pad_sequences(X_train, maxlen=max_length)\n",
    "X_test = pad_sequences(X_test, maxlen=max_length)\n",
    "\n",
    "word_index = tokenizer.word_index\n",
    "print('Found %s unique tokens.' % len(word_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Red Recurrente LSTM.\n",
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, LSTM, Embedding, Layer, SpatialDropout1D\n",
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "EMBEDDING_DIM = 100\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(max_words, EMBEDDING_DIM, input_length=X_train.shape[1]))\n",
    "model.add(SpatialDropout1D(0.2))\n",
    "model.add(LSTM(100, dropout=0.2, recurrent_dropout=0.2))\n",
    "model.add(Dense(2, activation='softmax'))\n",
    "model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, 250, 100)          50000     \n",
      "_________________________________________________________________\n",
      "spatial_dropout1d_1 (Spatial (None, 250, 100)          0         \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 100)               80400     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 2)                 202       \n",
      "=================================================================\n",
      "Total params: 130,602\n",
      "Trainable params: 130,602\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\veral\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow_core\\python\\framework\\indexed_slices.py:433: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1440000 samples, validate on 160000 samples\n",
      "Epoch 1/5\n",
      "1440000/1440000 [==============================] - 10878s 8ms/step - loss: 0.5422 - accuracy: 0.7154 - val_loss: 0.5350 - val_accuracy: 0.7212\n",
      "Epoch 2/5\n",
      "1440000/1440000 [==============================] - 10665s 7ms/step - loss: 0.5343 - accuracy: 0.7213 - val_loss: 0.5320 - val_accuracy: 0.7248\n",
      "Epoch 3/5\n",
      "1440000/1440000 [==============================] - 10759s 7ms/step - loss: 0.5309 - accuracy: 0.7241 - val_loss: 0.5292 - val_accuracy: 0.7256\n",
      "Epoch 4/5\n",
      "1440000/1440000 [==============================] - 10636s 7ms/step - loss: 0.5287 - accuracy: 0.7253 - val_loss: 0.5288 - val_accuracy: 0.7270\n",
      "Epoch 5/5\n",
      "1440000/1440000 [==============================] - 10628s 7ms/step - loss: 0.5272 - accuracy: 0.7263 - val_loss: 0.5272 - val_accuracy: 0.7276\n"
     ]
    }
   ],
   "source": [
    "epochs = 5\n",
    "batch_size = 64\n",
    "\n",
    "history = model.fit(X_train, y_train, epochs=epochs, batch_size=batch_size,validation_split=0.1,\n",
    "                    callbacks=[EarlyStopping(monitor='val_loss', patience=3, min_delta=0.0001)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 229
    },
    "colab_type": "code",
    "id": "NFx5Zx6n-ZnO",
    "outputId": "048a9891-c373-4e07-d191-f88839ab2040"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 1 1 1 1]\n",
      "[1 1 1 1 1]\n",
      "Accuracy: 0.7716\n",
      "F1: 0.7692\n",
      "Precision: 0.7811\n",
      "Recall: 0.7716\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.67      0.74       177\n",
      "           1       0.73      0.87      0.79       182\n",
      "\n",
      "    accuracy                           0.77       359\n",
      "   macro avg       0.78      0.77      0.77       359\n",
      "weighted avg       0.78      0.77      0.77       359\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# La evaluamos.\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, confusion_matrix, classification_report\n",
    "\n",
    "y_true = encoder.inverse_transform(y_test.reshape(-1))\n",
    "\n",
    "print(y_true[0:5])\n",
    "\n",
    "y_pred = model.predict_classes(X_test)\n",
    "y_pred = encoder.inverse_transform(y_pred.reshape(-1))\n",
    "\n",
    "print(y_pred[0:5])\n",
    "\n",
    "print('Accuracy: {acc:0.4f}'.format(acc=accuracy_score(y_true=y_true, y_pred=y_pred)))\n",
    "print('F1: {f1:0.4f}'.format(f1=f1_score(y_true=y_true, y_pred=y_pred, average='weighted')))\n",
    "print('Precision: {pre:0.4f}'.format(pre=precision_score(y_true=y_true, y_pred=y_pred, average='weighted')))\n",
    "print('Recall: {rec:0.4f}'.format(rec=recall_score(y_true=y_true, y_pred=y_pred, average='weighted')))\n",
    "print(classification_report(y_true=y_true, y_pred=y_pred))\n",
    "confusion_matrix = confusion_matrix(y_true=y_true, y_pred=y_pred, labels=[0, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 311
    },
    "colab_type": "code",
    "id": "QVR-cUo6-d-q",
    "outputId": "30019aee-8a79-4f2a-9452-14e687aada62"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import itertools\n",
    "\n",
    "def plot_confusion_matrix(cm, classes, title, cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    \"\"\"\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i, j], 'd'), horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "\n",
    "plt.figure()\n",
    "plot_confusion_matrix(confusion_matrix, classes=['negativo', 'positivo'],\n",
    "                      title='Matriz de Confusión')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusión.\n",
    "Como se puede observar la precisión alcanzada no es muy buena, pero esto no tiene porque estar directamente relacionado con las redes neronales, sino con el tratamiento previo que se ha realizado con los datos, ya que la normalización que se hizo con los textos es un poco básica y se podría mejorar (por ejemplo, podría haber palabras a las que se les haya añadido letras de más, \"looove\", o expresiones que caraterizan un comportamiento positivo, pero que no se han podido tomar en la tokenización de las palabras, por ejemplo el caso de la expresión lol, es un acrónimo en inglés que significa Laughing out loud, o Laugh out loud). También encontramos que la bolsa de palabras utilizada, podría ser mayor, pero interesaba la comparación entre los diferentes tipos de redes.\n",
    "\n",
    "Teniendo en cuenta esto si se puede apreciar que la red recurrente LSTM ha conseguido un  mejor aprendizaje de los textos en un menor número de épocas de aprendizaje, aunque se puede apreciar también que el tiempo de aprendizaje por época es sustancialmente mayor para la red LSTM.\n",
    "\n",
    "Por lo que se puede concluir que la red LSTM es más útil a la hora de clasificación de textos que una red neuronal simple, ya que una red neuronal recurrente no tiene una estructura de capas definida, sino que permiten conexiones arbitrarias entre las neuronas, incluso pudiendo crear ciclos, con esto se consigue crear la temporalidad, permitiendo que la red tenga memoria. Por lo que son redes muy potentes para todo lo que tiene que ver con el análisis de secuencias.\n",
    "\n",
    "Nota:\n",
    "No se han corregido los posibles fallos en la precisión mencionados anteriormente, para hacer énfasis en los diferentes factores implicados en el aprendizaje de las redes neuronales. Ya que como se ha podido observar, esta estaría relacionada no solo con el tipo de red utilizada (en este caso una simple y otra LSTM), sino también con la calidad del dato y su tratamiento previo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "@webio": {
   "lastCommId": null,
   "lastKernelId": null
  },
  "colab": {
   "collapsed_sections": [],
   "name": "Ej_Deep_Learning.ipynb",
   "provenance": [],
   "toc_visible": true,
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
